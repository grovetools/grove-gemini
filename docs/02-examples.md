This document provides a series of practical examples to demonstrate the capabilities of `grove-gemini`, from simple API calls to complex, context-aware development workflows.

## Example 1: Basic API Interaction

This example demonstrates the fundamental usage of the `gemapi request` command for direct interaction with the Gemini API, without automated context management.

### Making a Simple Request

The most direct way to use `gemapi` is to provide a prompt as an argument. The tool sends the request to the default model and prints the response to standard output.

```bash
gemapi request "What is the Go programming language?"
```

The output will be the Gemini API's response, streamed to your terminal.

### Using Files for Prompts and Outputs

For more complex prompts or to save the output, you can use files.

1.  **Create a prompt file:**

    ```bash
    echo "Write a simple 'Hello, World!' program in Go." > prompt.md
    ```

2.  **Run the request:**
    This command uses the `-f` flag to read the prompt from `prompt.md`, specifies a model with `-m`, and saves the generated code to `main.go` using the `-o` flag.

    ```bash
    gemapi request -f prompt.md -o main.go -m gemini-1.5-flash-latest
    ```

3.  **Verify the output:**
    The `main.go` file will now contain the Go code generated by the Gemini API.

    ```bash
    cat main.go
    ```
    ```go
    package main

    import "fmt"

    func main() {
        fmt.Println("Hello, World!")
    }
    ```

## Example 2: Context-Aware Development

`gemapi` integrates with `grove-context` to automatically include relevant files from your project in the request. This allows the model to understand your codebase and provide contextually accurate answers.

1.  **Set up the project:**
    Create a small Go project with two files.

    `main.go`:
    ```go
    package main

    import "fmt"

    func main() {
        message := GetGreeting()
        fmt.Println(message)
    }
    ```

    `greeting.go`:
    ```go
    package main

    func GetGreeting() string {
        return "Hello from a separate file!"
    }
    ```

2.  **Define the context rules:**
    Create a `.grove/rules` file to tell `gemapi` which files to include as context.

    ```bash
    mkdir -p .grove
    echo "*.go" > .grove/rules
    ```

3.  **Make a context-aware request:**
    Now, ask a question about the code. `gemapi` will find the `.grove/rules` file, gather all `.go` files, and attach them to the request.

    ```bash
    gemapi request "Based on the provided code, what will be printed when I run the program?"
    ```

    The model, having seen both `main.go` and `greeting.go`, will correctly determine the output.

    **Expected Output:**
    ```
    Based on the provided code, when you run the program, it will print:

    Hello from a separate file!
    ```

4.  **Forcing a context refresh:**
    If you change your `.grove/rules` file, you can force `gemapi` to regenerate the context files before making a request using the `--regenerate` flag.

    ```bash
    gemapi request --regenerate "Summarize the project based on the new rules."
    ```

## Example 3: Advanced Workflows with Caching and Observability

WARNING: EXPERIMENTAL

For large codebases, repeatedly uploading the same context is inefficient. `gemapi` uses the Gemini Caching API to store large, infrequently changing context, reducing cost and latency.

1.  **Enable Caching:**
    Caching is an opt-in feature. To enable it, add the `@enable-cache` directive to your `.grove/rules` file. This tells `gemapi` to use the files matched by the rules as "cold context" for caching.

    `.grove/rules`:
    ```
    @enable-cache
    *.go
    ```

2.  **Run the first request to create the cache:**
    The first time you make a request with caching enabled, `gemapi` will prompt you to confirm the creation of a new cache on Google's servers. The `--yes` flag can be used to skip this confirmation.

    ```bash
    gemapi request --yes "What is the purpose of the GetGreeting function?"
    ```

    You will see output indicating that a new cache is being created and files are being uploaded. This initial request may take longer.

3.  **Run a second request to use the cache:**
    Run another request. This time, `gemapi` will find the existing, valid cache and reuse it, only uploading any new or changed files. The request will be faster and cheaper.

    ```bash
    gemapi request "How is the greeting message generated?"
    ```

    The token usage summary will now show a significant number of `Cold (Cached)` tokens, indicating the cache was successfully used.

4.  **Observe Usage:**
    `gemapi` provides tools to inspect your API usage.

    *   **Inspect Caches**: Launch the interactive Terminal UI (TUI) to view and manage your caches.

        ```bash
        gemapi cache tui
        ```
        This interface shows all local and remote caches, their status, usage statistics, and cost savings.

    *   **Query Local Logs**: You can view a detailed log of your recent requests, including token counts, costs, and cache hit rates.

        ```bash
        gemapi query local --hours 1
        ```
        This command displays a table of all requests made in the last hour, allowing you to see how caching impacts token consumption.

    *   **Query Billing Data**: For a complete cost picture, you can query your Google Cloud billing data directly from BigQuery (requires a one-time setup of billing export in your GCP account).

        ```bash
        gemapi query billing \
          --project-id your-gcp-project \
          --dataset-id your_billing_dataset \
          --table-id your_billing_table
        ```
